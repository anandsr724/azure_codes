{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import functools\n",
    "import json\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "from confluent_kafka import Producer, Consumer\n",
    "from confluent_kafka.serialization import StringSerializer\n",
    "import requests\n",
    "\n",
    "\n",
    "class DataStoreType(Enum):\n",
    "    \"\"\"Enumeration of supported data store types\"\"\"\n",
    "    KAFKA = \"kafka\"\n",
    "    ADLS = \"adls\"\n",
    "\n",
    "\n",
    "class ApplicationConfig:\n",
    "    \"\"\"\n",
    "    Central application configuration that manages environment-specific configurations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._config_dict = {\n",
    "            \"nonprod\": {\n",
    "                # Kafka Configuration\n",
    "                \"kafka\": {\n",
    "                    \"bootstrap-servers\": \"nonprod-kafka-broker1:9092,nonprod-kafka-broker2:9092\",\n",
    "                    \"client-id-key\": \"nonprod-kafka-client-id\",\n",
    "                    \"client-secret-key\": \"nonprod-kafka-client-secret\",\n",
    "                    \"token-url\": \"https://nonprod-auth.company.com/oauth/token\",\n",
    "                    \"ssl-ca-location\": \"kafka-nonprod.pem\",\n",
    "                    \"default-group-id\": \"nonprod-insurance-data-eng\"\n",
    "                },\n",
    "                # ADLS Configuration\n",
    "                \"adls\": {\n",
    "                    \"client-id-key\": \"nonprod-adls-client-id\",\n",
    "                    \"client-secret-key\": \"nonprod-adls-client-secret\",\n",
    "                    \"tenant-id-key\": \"nonprod-tenant-id\"  # Changed to key reference\n",
    "                },\n",
    "                # Common Configuration\n",
    "                \"default-secret-scope\": \"nonprod-secrets\"\n",
    "            },\n",
    "            \"prod\": {\n",
    "                # Kafka Configuration\n",
    "                \"kafka\": {\n",
    "                    \"bootstrap-servers\": \"prod-kafka-broker1:9092,prod-kafka-broker2:9092\",\n",
    "                    \"client-id-key\": \"prod-kafka-client-id\",\n",
    "                    \"client-secret-key\": \"prod-kafka-client-secret\",\n",
    "                    \"token-url\": \"https://prod-auth.company.com/oauth/token\",\n",
    "                    \"ssl-ca-location\": \"kafka-prod.pem\",\n",
    "                    \"default-group-id\": \"prod-insurance-data-eng\"\n",
    "                },\n",
    "                # ADLS Configuration\n",
    "                \"adls\": {\n",
    "                    \"client-id-key\": \"prod-adls-client-id\", \n",
    "                    \"client-secret-key\": \"prod-adls-client-secret\",\n",
    "                    \"tenant-id-key\": \"prod-tenant-id\"  # Changed to key reference\n",
    "                },\n",
    "                # Common Configuration\n",
    "                \"default-secret-scope\": \"prod-secrets\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_config_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the complete configuration dictionary\"\"\"\n",
    "        return self._config_dict.copy()\n",
    "    \n",
    "    def get_configuration(self, env: str, service_type: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get configuration for a specific environment and service type\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment name ('prod' or 'nonprod')\n",
    "            service_type (str): Service type ('kafka', 'adls', etc.)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Configuration dictionary for the service\n",
    "        \"\"\"\n",
    "        if env not in self._config_dict:\n",
    "            raise ValueError(f\"Environment '{env}' not found in configurations\")\n",
    "        \n",
    "        env_config = self._config_dict[env]\n",
    "        \n",
    "        if service_type not in env_config:\n",
    "            raise ValueError(f\"Service type '{service_type}' not found for environment '{env}'\")\n",
    "        \n",
    "        # Merge service-specific config with common config\n",
    "        config = env_config[service_type].copy()\n",
    "        config['default-secret-scope'] = env_config['default-secret-scope']\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def add_environment_config(self, env: str, service_type: str, config_dict: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Add or update configuration for an environment and service type\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment name\n",
    "            service_type (str): Service type\n",
    "            config_dict (dict): Configuration dictionary\n",
    "        \"\"\"\n",
    "        if env not in self._config_dict:\n",
    "            self._config_dict[env] = {}\n",
    "        \n",
    "        self._config_dict[env][service_type] = config_dict\n",
    "\n",
    "\n",
    "class ConfigurationService:\n",
    "    \"\"\"\n",
    "    Configuration service that provides a unified interface for accessing configurations\n",
    "    and resolving secrets from Databricks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, application_config: Optional[ApplicationConfig] = None):\n",
    "        self.application_config = application_config or ApplicationConfig()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def get_configuration(self, env: str, service_type: str = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get configuration for environment and optional service type\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment name\n",
    "            service_type (str): Optional service type filter\n",
    "            \n",
    "        Returns:\n",
    "            dict: Configuration dictionary\n",
    "        \"\"\"\n",
    "        if service_type:\n",
    "            return self.application_config.get_configuration(env, service_type)\n",
    "        else:\n",
    "            # Return all configurations for the environment\n",
    "            return self.application_config.get_config_dict()[env]\n",
    "    \n",
    "    def get_resolved_configuration(self, env: str, service_type: str, \n",
    "                                 custom_secret_scope: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get configuration with secrets resolved from Databricks\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment name\n",
    "            service_type (str): Service type\n",
    "            custom_secret_scope (str): Optional custom secret scope\n",
    "            \n",
    "        Returns:\n",
    "            dict: Configuration with resolved secret values\n",
    "        \"\"\"\n",
    "        config = self.get_configuration(env, service_type)\n",
    "        secret_scope = custom_secret_scope or config.get('default-secret-scope')\n",
    "        \n",
    "        resolved_config = config.copy()\n",
    "        \n",
    "        # Resolve secrets for keys that end with '-key'\n",
    "        for key, value in config.items():\n",
    "            if key.endswith('-key'):\n",
    "                try:\n",
    "                    resolved_value = self._get_secret(secret_scope, value)\n",
    "                    # Store resolved value with new key name (remove '-key' suffix)\n",
    "                    resolved_key = key.replace('-key', '')\n",
    "                    resolved_config[resolved_key] = resolved_value\n",
    "                    self.logger.info(f\"Resolved secret for {key}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Failed to resolve secret for {key}: {str(e)}\")\n",
    "                    raise Exception(f\"Failed to resolve secret for {key}: {str(e)}\")\n",
    "        \n",
    "        return resolved_config\n",
    "    \n",
    "    def _get_secret(self, scope: str, key: str) -> str:\n",
    "        \"\"\"\n",
    "        Get secret value from Databricks secret scope\n",
    "        \n",
    "        Args:\n",
    "            scope (str): Secret scope name\n",
    "            key (str): Secret key name\n",
    "            \n",
    "        Returns:\n",
    "            str: Secret value\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # In a real Databricks environment, this would be:\n",
    "            # return dbutils.secrets.get(scope, key)\n",
    "            \n",
    "            # For demonstration/testing purposes:\n",
    "            return f\"resolved_secret_from_{scope}_{key}\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to retrieve secret '{key}' from scope '{scope}': {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class DataStoreConnectionFactory:\n",
    "    \"\"\"\n",
    "    Factory class for creating data store connections based on type\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_connection(datastore_type: DataStoreType, env: str, \n",
    "                         config_service: Optional[ConfigurationService] = None,\n",
    "                         **kwargs):\n",
    "        \"\"\"\n",
    "        Create a connection based on the datastore type\n",
    "        \n",
    "        Args:\n",
    "            datastore_type (DataStoreType): Type of datastore to connect to\n",
    "            env (str): Environment name\n",
    "            config_service (ConfigurationService): Configuration service instance\n",
    "            **kwargs: Additional arguments for specific connectors\n",
    "            \n",
    "        Returns:\n",
    "            Connection object based on the datastore type\n",
    "        \"\"\"\n",
    "        config_service = config_service or ConfigurationService()\n",
    "        \n",
    "        if datastore_type == DataStoreType.ADLS:\n",
    "            return ADLSConnector(env=env, config_service=config_service, **kwargs)\n",
    "        elif datastore_type == DataStoreType.KAFKA:\n",
    "            return KafkaProducer(env=env, config_service=config_service, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported datastore type: {datastore_type}\")\n",
    "\n",
    "\n",
    "class ADLSConnector:\n",
    "    \"\"\"\n",
    "    Azure Data Lake Storage connector implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, env: str = 'nonprod', config_service: Optional[ConfigurationService] = None, \n",
    "                 safe_parent_path: str = \"/mnt/temp\", custom_secret_scope: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the ADLS connector\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment ('prod' or 'nonprod')\n",
    "            config_service (ConfigurationService): Configuration service instance\n",
    "            safe_parent_path (str): Safe parent path for operations\n",
    "            custom_secret_scope (str): Optional custom secret scope\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.config_service = config_service or ConfigurationService()\n",
    "        self.safe_parent_path = safe_parent_path\n",
    "        self.custom_secret_scope = custom_secret_scope\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Get resolved configuration (secrets resolved by ConfigurationService)\n",
    "        self.env_config = self.config_service.get_resolved_configuration(\n",
    "            env, 'adls', custom_secret_scope\n",
    "        )\n",
    "        \n",
    "        self.config_dict = None\n",
    "        self.source_path = None\n",
    "        self.mount_point = None\n",
    "        self.is_mounted = False\n",
    "        \n",
    "    def setup_connection(self, storage_account_name: str, container_name: str, \n",
    "                        mount_name: str, subfolder_path: str = \"\"):\n",
    "        \"\"\"\n",
    "        Set up the ADLS connection configuration\n",
    "        \n",
    "        Args:\n",
    "            storage_account_name (str): Azure storage account name\n",
    "            container_name (str): Container name\n",
    "            mount_name (str): Local mount name\n",
    "            subfolder_path (str): Optional subfolder path\n",
    "        \"\"\"\n",
    "        # Use resolved secrets from configuration service\n",
    "        client_id = self.env_config['client-id']\n",
    "        client_secret = self.env_config['client-secret']\n",
    "        tenant_id = self.env_config['tenant-id']\n",
    "        \n",
    "        # Build Azure storage path\n",
    "        self.source_path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/{subfolder_path}\"\n",
    "        self.mount_point = f\"/mnt/{mount_name}\"\n",
    "        \n",
    "        # Create OAuth configuration\n",
    "        self.config_dict = {\n",
    "            \"fs.azure.account.auth.type\": \"OAuth\",\n",
    "            \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "            \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "            \"fs.azure.account.oauth2.client.secret\": client_secret,\n",
    "            \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"\n",
    "        }\n",
    "        \n",
    "        self.logger.info(f\"ADLS configuration set up for {self.env} environment\")\n",
    "        self.logger.info(f\"Source: {self.source_path}, Mount: {self.mount_point}\")\n",
    "    \n",
    "    def mount(self):\n",
    "        \"\"\"Mount the ADLS storage to Databricks file system\"\"\"\n",
    "        if not self.config_dict:\n",
    "            raise Exception(\"Configuration not set up. Call setup_connection() first.\")\n",
    "        \n",
    "        try:\n",
    "            # In real Databricks environment:\n",
    "            # dbutils.fs.mount(\n",
    "            #     source=self.source_path,\n",
    "            #     mount_point=self.mount_point,\n",
    "            #     extra_configs=self.config_dict\n",
    "            # )\n",
    "            self.is_mounted = True\n",
    "            self.logger.info(f\"Successfully mounted {self.source_path} at {self.mount_point}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            if \"already mounted\" in str(e).lower():\n",
    "                self.is_mounted = True\n",
    "                self.logger.info(f\"{self.mount_point} already mounted\")\n",
    "            else:\n",
    "                self.logger.error(f\"Failed to mount ADLS: {str(e)}\")\n",
    "                raise Exception(f\"Failed to mount ADLS: {str(e)}\")\n",
    "    \n",
    "    def unmount(self):\n",
    "        \"\"\"Unmount the ADLS storage\"\"\"\n",
    "        if not self.mount_point:\n",
    "            raise Exception(\"No mount point configured\")\n",
    "            \n",
    "        try:\n",
    "            # In real Databricks environment:\n",
    "            # dbutils.fs.unmount(self.mount_point)\n",
    "            self.is_mounted = False\n",
    "            self.logger.info(f\"Successfully unmounted {self.mount_point}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Could not unmount {self.mount_point}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class KafkaProducer:\n",
    "    \"\"\"\n",
    "    Kafka producer for publishing messages to topics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, env: str = 'nonprod', topic_name: Optional[str] = None, \n",
    "                 config_service: Optional[ConfigurationService] = None, \n",
    "                 custom_secret_scope: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the Kafka producer\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment ('prod' or 'nonprod')\n",
    "            topic_name (str): Default topic name\n",
    "            config_service (ConfigurationService): Configuration service instance\n",
    "            custom_secret_scope (str): Custom secret scope\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.topic_name = topic_name\n",
    "        self.config_service = config_service or ConfigurationService()\n",
    "        self.custom_secret_scope = custom_secret_scope\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Get resolved configuration (secrets resolved by ConfigurationService)\n",
    "        self.env_config = self.config_service.get_resolved_configuration(\n",
    "            env, 'kafka', custom_secret_scope\n",
    "        )\n",
    "        \n",
    "        # Setup credentials from resolved config\n",
    "        self.client_id = self.env_config['client-id']\n",
    "        self.client_secret = self.env_config['client-secret']\n",
    "        self.bootstrap_servers = self.env_config['bootstrap-servers']\n",
    "        self.token_url = self.env_config['token-url']\n",
    "        self.ssl_ca_location = self.env_config['ssl-ca-location']\n",
    "        \n",
    "        # Create producer\n",
    "        self.producer = Producer(self._get_producer_config())\n",
    "        self.serializer = StringSerializer('utf8')\n",
    "        \n",
    "        self.logger.info(f\"Kafka Producer initialized for {self.env} environment\")\n",
    "        self.logger.info(f\"Bootstrap servers: {self.bootstrap_servers}\")\n",
    "    \n",
    "    def _get_token(self, config):\n",
    "        \"\"\"Get OAuth token for authentication\"\"\"\n",
    "        payload = {\n",
    "            'grant_type': 'client_credentials',\n",
    "            'scope': 'kafka'\n",
    "        }\n",
    "        \n",
    "        resp = requests.post(\n",
    "            self.token_url,\n",
    "            auth=(self.client_id, self.client_secret),\n",
    "            data=payload\n",
    "        )\n",
    "        \n",
    "        token = resp.json()\n",
    "        return token['access_token'], time.time() + float(token['expires_in'])\n",
    "    \n",
    "    def _get_producer_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get producer configuration\"\"\"\n",
    "        return {\n",
    "            'bootstrap.servers': self.bootstrap_servers,\n",
    "            'security.protocol': 'sasl_ssl',\n",
    "            'sasl.mechanisms': 'OAUTHBEARER',\n",
    "            'ssl.ca.location': self.ssl_ca_location,\n",
    "            'oauth_cb': functools.partial(self._get_token),\n",
    "            'logger': self.logger,\n",
    "        }\n",
    "    \n",
    "    def send_message(self, message: Union[Dict, str], topic_name: Optional[str] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Send a message to the specified topic\n",
    "        \n",
    "        Args:\n",
    "            message (dict or str): Message to send\n",
    "            topic_name (str): Topic to send to\n",
    "            \n",
    "        Returns:\n",
    "            bool: Success status\n",
    "        \"\"\"\n",
    "        if not topic_name and not self.topic_name:\n",
    "            raise Exception(\"No topic specified. Provide topic_name parameter or set default topic.\")\n",
    "            \n",
    "        target_topic = topic_name or self.topic_name\n",
    "        \n",
    "        # Convert message to JSON string if it's a dict\n",
    "        if isinstance(message, dict):\n",
    "            message = json.dumps(message)\n",
    "        \n",
    "        try:\n",
    "            self.producer.produce(target_topic, value=message)\n",
    "            self.producer.flush()\n",
    "            self.logger.info(f\"Message sent to topic '{target_topic}'\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to send message: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the producer connection\"\"\"\n",
    "        self.producer.flush()\n",
    "        self.logger.info(\"Producer closed\")\n",
    "\n",
    "\n",
    "# Usage Examples:\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Using the factory pattern\n",
    "    config_service = ConfigurationService()\n",
    "    \n",
    "    # Create ADLS connection using factory\n",
    "    adls_conn = DataStoreConnectionFactory.create_connection(\n",
    "        DataStoreType.ADLS, \n",
    "        env='nonprod',\n",
    "        config_service=config_service\n",
    "    )\n",
    "    \n",
    "    # Create Kafka connection using factory\n",
    "    kafka_conn = DataStoreConnectionFactory.create_connection(\n",
    "        DataStoreType.KAFKA,\n",
    "        env='nonprod', \n",
    "        config_service=config_service,\n",
    "        topic_name='my-topic'\n",
    "    )\n",
    "    \n",
    "    # Example 2: Direct instantiation (still works)\n",
    "    adls_direct = ADLSConnector(env='prod', config_service=config_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e81445",
   "metadata": {},
   "source": [
    "Option 1: Add a convenience method to the factory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStoreConnectionFactory:\n",
    "    \"\"\"\n",
    "    Factory class for creating data store connections based on type\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_connection(datastore_type: DataStoreType, env: str, \n",
    "                         config_service: Optional[ConfigurationService] = None,\n",
    "                         auth_service: Optional[AuthenticationService] = None,\n",
    "                         **kwargs):\n",
    "        \"\"\"\n",
    "        Create a connection based on the datastore type\n",
    "        \n",
    "        Args:\n",
    "            datastore_type (DataStoreType): Type of datastore to connect to\n",
    "            env (str): Environment name\n",
    "            config_service (ConfigurationService): Configuration service instance\n",
    "            auth_service (AuthenticationService): Optional authentication service\n",
    "            **kwargs: Additional arguments for specific connectors\n",
    "            \n",
    "        Returns:\n",
    "            Connection object based on the datastore type\n",
    "        \"\"\"\n",
    "        config_service = config_service or ConfigurationService()\n",
    "        \n",
    "        if datastore_type == DataStoreType.ADLS:\n",
    "            return ADLSConnector(env=env, config_service=config_service, **kwargs)\n",
    "        elif datastore_type == DataStoreType.KAFKA:\n",
    "            return KafkaProducer(\n",
    "                env=env, \n",
    "                config_service=config_service,\n",
    "                auth_service=auth_service,\n",
    "                **kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported datastore type: {datastore_type}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_adls_connection(env: str, storage_account: str, container: str, \n",
    "                              mount_name: str, subfolder: str = \"\", \n",
    "                              config_service: Optional[ConfigurationService] = None,\n",
    "                              custom_secret_scope: Optional[str] = None,\n",
    "                              safe_parent_path: str = \"/mnt/temp\",\n",
    "                              auto_mount: bool = True) -> 'ADLSConnector':\n",
    "        \"\"\"\n",
    "        Quick helper function to create and mount ADLS connection\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment name\n",
    "            storage_account (str): Azure storage account name\n",
    "            container (str): Container name\n",
    "            mount_name (str): Local mount name\n",
    "            subfolder (str): Optional subfolder path\n",
    "            config_service (ConfigurationService): Configuration service instance\n",
    "            custom_secret_scope (str): Custom secret scope\n",
    "            safe_parent_path (str): Safe parent path for operations\n",
    "            auto_mount (bool): Whether to automatically mount after setup\n",
    "            \n",
    "        Returns:\n",
    "            ADLSConnector: Configured and optionally mounted connector\n",
    "        \"\"\"\n",
    "        connector = DataStoreConnectionFactory.create_connection(\n",
    "            DataStoreType.ADLS,\n",
    "            env=env,\n",
    "            config_service=config_service,\n",
    "            custom_secret_scope=custom_secret_scope,\n",
    "            safe_parent_path=safe_parent_path\n",
    "        )\n",
    "        \n",
    "        connector.setup_connection(storage_account, container, mount_name, subfolder)\n",
    "        \n",
    "        if auto_mount:\n",
    "            connector.mount()\n",
    "        \n",
    "        return connector\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_kafka_producer(env: str, topic_name: Optional[str] = None,\n",
    "                             config_service: Optional[ConfigurationService] = None,\n",
    "                             auth_service: Optional[AuthenticationService] = None,\n",
    "                             custom_secret_scope: Optional[str] = None) -> 'KafkaProducer':\n",
    "        \"\"\"\n",
    "        Quick helper function to create Kafka producer\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment name\n",
    "            topic_name (str): Default topic name\n",
    "            config_service (ConfigurationService): Configuration service instance\n",
    "            auth_service (AuthenticationService): Authentication service\n",
    "            custom_secret_scope (str): Custom secret scope\n",
    "            \n",
    "        Returns:\n",
    "            KafkaProducer: Configured producer\n",
    "        \"\"\"\n",
    "        return DataStoreConnectionFactory.create_connection(\n",
    "            DataStoreType.KAFKA,\n",
    "            env=env,\n",
    "            topic_name=topic_name,\n",
    "            config_service=config_service,\n",
    "            auth_service=auth_service,\n",
    "            custom_secret_scope=custom_secret_scope\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage with Option 1:\n",
    "# Your familiar pattern - now with the factory!\n",
    "adls = DataStoreConnectionFactory.create_adls_connection(\n",
    "    env='nonprod',\n",
    "    storage_account='myadls',\n",
    "    container='analytics-data',\n",
    "    mount_name='analytics_dev',\n",
    "    custom_secret_scope='my-secrets'  # Note: parameter name changed\n",
    ")\n",
    "\n",
    "# Use it immediately\n",
    "files = adls.list_files()\n",
    "\n",
    "# Same for Kafka\n",
    "kafka = DataStoreConnectionFactory.create_kafka_producer(\n",
    "    env='prod',\n",
    "    topic_name='my-topic'\n",
    ")\n",
    "kafka.send_message({\"key\": \"value\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c3d81",
   "metadata": {},
   "source": [
    "authservice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "import requests\n",
    "\n",
    "\n",
    "class AuthenticationService(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for authentication services\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_token(self) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Get authentication token\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[str, float]: (token, expiry_timestamp)\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def is_token_valid(self, expiry_timestamp: float) -> bool:\n",
    "        \"\"\"\n",
    "        Check if token is still valid\n",
    "        \n",
    "        Args:\n",
    "            expiry_timestamp (float): Token expiry timestamp\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if token is valid\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class OAuthAuthenticationService(AuthenticationService):\n",
    "    \"\"\"\n",
    "    OAuth-based authentication service for getting tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, client_id: str, client_secret: str, token_url: str, \n",
    "                 scope: str = \"kafka\", grant_type: str = \"client_credentials\"):\n",
    "        \"\"\"\n",
    "        Initialize OAuth authentication service\n",
    "        \n",
    "        Args:\n",
    "            client_id (str): OAuth client ID\n",
    "            client_secret (str): OAuth client secret\n",
    "            token_url (str): Token endpoint URL\n",
    "            scope (str): OAuth scope\n",
    "            grant_type (str): OAuth grant type\n",
    "        \"\"\"\n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        self.token_url = token_url\n",
    "        self.scope = scope\n",
    "        self.grant_type = grant_type\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Token cache\n",
    "        self._cached_token = None\n",
    "        self._token_expiry = 0\n",
    "    \n",
    "    def get_token(self) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Get OAuth token, using cache if valid\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[str, float]: (access_token, expiry_timestamp)\n",
    "        \"\"\"\n",
    "        # Return cached token if still valid\n",
    "        if self._cached_token and self.is_token_valid(self._token_expiry):\n",
    "            self.logger.debug(\"Using cached OAuth token\")\n",
    "            return self._cached_token, self._token_expiry\n",
    "        \n",
    "        # Get new token\n",
    "        self.logger.info(\"Requesting new OAuth token\")\n",
    "        token, expiry = self._request_new_token()\n",
    "        \n",
    "        # Cache the token\n",
    "        self._cached_token = token\n",
    "        self._token_expiry = expiry\n",
    "        \n",
    "        return token, expiry\n",
    "    \n",
    "    def _request_new_token(self) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Request a new OAuth token from the server\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[str, float]: (access_token, expiry_timestamp)\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            'grant_type': self.grant_type,\n",
    "            'scope': self.scope\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                self.token_url,\n",
    "                auth=(self.client_id, self.client_secret),\n",
    "                data=payload,\n",
    "                timeout=30  # Add timeout for safety\n",
    "            )\n",
    "            response.raise_for_status()  # Raise exception for HTTP errors\n",
    "            \n",
    "            token_data = response.json()\n",
    "            access_token = token_data['access_token']\n",
    "            expires_in = float(token_data['expires_in'])\n",
    "            \n",
    "            # Calculate expiry timestamp (with small buffer for safety)\n",
    "            expiry_timestamp = time.time() + expires_in - 30  # 30 second buffer\n",
    "            \n",
    "            self.logger.info(f\"Successfully obtained OAuth token, expires in {expires_in} seconds\")\n",
    "            return access_token, expiry_timestamp\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            self.logger.error(f\"Failed to obtain OAuth token: {str(e)}\")\n",
    "            raise Exception(f\"OAuth token request failed: {str(e)}\")\n",
    "        except KeyError as e:\n",
    "            self.logger.error(f\"Invalid token response format: missing {str(e)}\")\n",
    "            raise Exception(f\"Invalid token response: missing {str(e)}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Unexpected error during token request: {str(e)}\")\n",
    "            raise Exception(f\"Token request error: {str(e)}\")\n",
    "    \n",
    "    def is_token_valid(self, expiry_timestamp: float) -> bool:\n",
    "        \"\"\"\n",
    "        Check if token is still valid\n",
    "        \n",
    "        Args:\n",
    "            expiry_timestamp (float): Token expiry timestamp\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if token is valid\n",
    "        \"\"\"\n",
    "        return time.time() < expiry_timestamp\n",
    "    \n",
    "    def invalidate_cache(self):\n",
    "        \"\"\"Invalidate cached token to force refresh on next request\"\"\"\n",
    "        self._cached_token = None\n",
    "        self._token_expiry = 0\n",
    "        self.logger.info(\"OAuth token cache invalidated\")\n",
    "\n",
    "\n",
    "class AuthenticationServiceFactory:\n",
    "    \"\"\"\n",
    "    Factory for creating authentication services\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_oauth_service(client_id: str, client_secret: str, token_url: str, \n",
    "                           scope: str = \"kafka\") -> OAuthAuthenticationService:\n",
    "        \"\"\"\n",
    "        Create OAuth authentication service\n",
    "        \n",
    "        Args:\n",
    "            client_id (str): OAuth client ID\n",
    "            client_secret (str): OAuth client secret\n",
    "            token_url (str): Token endpoint URL\n",
    "            scope (str): OAuth scope\n",
    "            \n",
    "        Returns:\n",
    "            OAuthAuthenticationService: Configured OAuth service\n",
    "        \"\"\"\n",
    "        return OAuthAuthenticationService(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "            token_url=token_url,\n",
    "            scope=scope\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f1da3",
   "metadata": {},
   "source": [
    "new kafka producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32784d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import functools\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "from confluent_kafka import Producer\n",
    "from confluent_kafka.serialization import StringSerializer\n",
    "\n",
    "# Import the new authentication service\n",
    "from authentication_service import AuthenticationService, AuthenticationServiceFactory\n",
    "\n",
    "\n",
    "class KafkaProducer:\n",
    "    \"\"\"\n",
    "    Kafka producer for publishing messages to topics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, env: str = 'nonprod', topic_name: Optional[str] = None, \n",
    "                 config_service: Optional[ConfigurationService] = None, \n",
    "                 custom_secret_scope: Optional[str] = None,\n",
    "                 auth_service: Optional[AuthenticationService] = None):\n",
    "        \"\"\"\n",
    "        Initialize the Kafka producer\n",
    "        \n",
    "        Args:\n",
    "            env (str): Environment ('prod' or 'nonprod')\n",
    "            topic_name (str): Default topic name\n",
    "            config_service (ConfigurationService): Configuration service instance\n",
    "            custom_secret_scope (str): Custom secret scope\n",
    "            auth_service (AuthenticationService): Optional authentication service\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.topic_name = topic_name\n",
    "        self.config_service = config_service or ConfigurationService()\n",
    "        self.custom_secret_scope = custom_secret_scope\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Get resolved configuration (secrets resolved by ConfigurationService)\n",
    "        self.env_config = self.config_service.get_resolved_configuration(\n",
    "            env, 'kafka', custom_secret_scope\n",
    "        )\n",
    "        \n",
    "        # Setup authentication service\n",
    "        self.auth_service = auth_service or self._create_default_auth_service()\n",
    "        \n",
    "        # Setup other configuration\n",
    "        self.bootstrap_servers = self.env_config['bootstrap-servers']\n",
    "        self.ssl_ca_location = self.env_config['ssl-ca-location']\n",
    "        \n",
    "        # Create producer\n",
    "        self.producer = Producer(self._get_producer_config())\n",
    "        self.serializer = StringSerializer('utf8')\n",
    "        \n",
    "        self.logger.info(f\"Kafka Producer initialized for {self.env} environment\")\n",
    "        self.logger.info(f\"Bootstrap servers: {self.bootstrap_servers}\")\n",
    "    \n",
    "    def _create_default_auth_service(self) -> AuthenticationService:\n",
    "        \"\"\"\n",
    "        Create default OAuth authentication service from configuration\n",
    "        \n",
    "        Returns:\n",
    "            AuthenticationService: Configured authentication service\n",
    "        \"\"\"\n",
    "        return AuthenticationServiceFactory.create_oauth_service(\n",
    "            client_id=self.env_config['client-id'],\n",
    "            client_secret=self.env_config['client-secret'],\n",
    "            token_url=self.env_config['token-url'],\n",
    "            scope='kafka'\n",
    "        )\n",
    "    \n",
    "    def _get_token_callback(self, config):\n",
    "        \"\"\"\n",
    "        OAuth token callback for Kafka producer\n",
    "        This method is called by the Kafka library when it needs a token\n",
    "        \n",
    "        Args:\n",
    "            config: Kafka configuration (provided by confluent-kafka)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple: (token, expiry_timestamp)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            token, expiry = self.auth_service.get_token()\n",
    "            self.logger.debug(\"OAuth token provided to Kafka producer\")\n",
    "            return token, expiry\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to get OAuth token for Kafka: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _get_producer_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get producer configuration with OAuth callback\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, Any]: Kafka producer configuration\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'bootstrap.servers': self.bootstrap_servers,\n",
    "            'security.protocol': 'sasl_ssl',\n",
    "            'sasl.mechanisms': 'OAUTHBEARER',\n",
    "            'ssl.ca.location': self.ssl_ca_location,\n",
    "            'oauth_cb': self._get_token_callback,  # Use our callback method\n",
    "            'logger': self.logger,\n",
    "        }\n",
    "    \n",
    "    def send_message(self, message: Union[Dict, str], topic_name: Optional[str] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Send a message to the specified topic\n",
    "        \n",
    "        Args:\n",
    "            message (dict or str): Message to send\n",
    "            topic_name (str): Topic to send to\n",
    "            \n",
    "        Returns:\n",
    "            bool: Success status\n",
    "        \"\"\"\n",
    "        if not topic_name and not self.topic_name:\n",
    "            raise Exception(\"No topic specified. Provide topic_name parameter or set default topic.\")\n",
    "            \n",
    "        target_topic = topic_name or self.topic_name\n",
    "        \n",
    "        # Convert message to JSON string if it's a dict\n",
    "        if isinstance(message, dict):\n",
    "            message = json.dumps(message)\n",
    "        \n",
    "        try:\n",
    "            self.producer.produce(target_topic, value=message)\n",
    "            self.producer.flush()\n",
    "            self.logger.info(f\"Message sent to topic '{target_topic}'\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to send message: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def refresh_authentication(self):\n",
    "        \"\"\"\n",
    "        Force refresh of authentication token\n",
    "        Useful when token expires or authentication fails\n",
    "        \"\"\"\n",
    "        if hasattr(self.auth_service, 'invalidate_cache'):\n",
    "            self.auth_service.invalidate_cache()\n",
    "            self.logger.info(\"Authentication cache invalidated\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the producer connection\"\"\"\n",
    "        self.producer.flush()\n",
    "        self.logger.info(\"Producer closed\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6d7d6",
   "metadata": {},
   "source": [
    "updated factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6519438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStoreConnectionFactory:\n",
    "    \"\"\"\n",
    "    Factory class for creating data store connections based on type\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_connection(datastore_type: DataStoreType, env: str, \n",
    "                         config_service: Optional[ConfigurationService] = None,\n",
    "                         auth_service: Optional[AuthenticationService] = None,\n",
    "                         **kwargs):\n",
    "        \"\"\"\n",
    "        Create a connection based on the datastore type\n",
    "        \n",
    "        Args:\n",
    "            datastore_type (DataStoreType): Type of datastore to connect to\n",
    "            env (str): Environment name\n",
    "            config_service (ConfigurationService): Configuration service instance\n",
    "            auth_service (AuthenticationService): Optional authentication service\n",
    "            **kwargs: Additional arguments for specific connectors\n",
    "            \n",
    "        Returns:\n",
    "            Connection object based on the datastore type\n",
    "        \"\"\"\n",
    "        config_service = config_service or ConfigurationService()\n",
    "        \n",
    "        if datastore_type == DataStoreType.ADLS:\n",
    "            return ADLSConnector(env=env, config_service=config_service, **kwargs)\n",
    "        elif datastore_type == DataStoreType.KAFKA:\n",
    "            return KafkaProducer(\n",
    "                env=env, \n",
    "                config_service=config_service,\n",
    "                auth_service=auth_service,  # Pass auth service to Kafka\n",
    "                **kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported datastore type: {datastore_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5281d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example 1: Using default authentication (factory creates it)\n",
    "kafka_producer = DataStoreConnectionFactory.create_connection(\n",
    "    DataStoreType.KAFKA,\n",
    "    env='prod',\n",
    "    topic_name='my-topic'\n",
    ")\n",
    "\n",
    "# Example 2: Using custom authentication service\n",
    "custom_auth = AuthenticationServiceFactory.create_oauth_service(\n",
    "    client_id=\"my_client\",\n",
    "    client_secret=\"my_secret\", \n",
    "    token_url=\"https://auth.company.com/token\",\n",
    "    scope=\"kafka\"\n",
    ")\n",
    "\n",
    "kafka_producer = DataStoreConnectionFactory.create_connection(\n",
    "    DataStoreType.KAFKA,\n",
    "    env='prod',\n",
    "    auth_service=custom_auth,\n",
    "    topic_name='my-topic'\n",
    ")\n",
    "\n",
    "# Example 3: Force token refresh if needed\n",
    "kafka_producer.refresh_authentication()\n",
    "\n",
    "# Example 4: Direct authentication service usage\n",
    "auth_service = AuthenticationServiceFactory.create_oauth_service(\n",
    "    client_id=\"test\", \n",
    "    client_secret=\"secret\",\n",
    "    token_url=\"https://auth.example.com\"\n",
    ")\n",
    "\n",
    "token, expiry = auth_service.get_token()\n",
    "print(f\"Token: {token[:20]}..., Expires: {expiry}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
