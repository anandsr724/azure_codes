{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationService:\n",
    "    \"\"\"\n",
    "    Central configuration service that manages environment-specific configurations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._configurations = {\n",
    "            \"nonprod\": {\n",
    "                \"tenant-id\": \"nonprod-tenant-id-value\",\n",
    "                \"client-id-key\": \"nonprod-client-id\",\n",
    "                \"client-secret-key\": \"nonprod-client-secret\",\n",
    "                \"default-secret-scope\": \"nonprod-adls-secrets\"\n",
    "            },\n",
    "            \"prod\": {\n",
    "                \"tenant-id\": \"prod-tenant-id-value\", \n",
    "                \"client-id-key\": \"prod-client-id\",\n",
    "                \"client-secret-key\": \"prod-client-secret\",\n",
    "                \"default-secret-scope\": \"prod-adls-secrets\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_configuration(self, environment):\n",
    "        \"\"\"\n",
    "        Get configuration dictionary for a specific environment\n",
    "        \n",
    "        Args:\n",
    "            environment (str): Environment name ('prod' or 'nonprod')\n",
    "            \n",
    "        Returns:\n",
    "            dict: Configuration dictionary for the environment\n",
    "        \"\"\"\n",
    "        if environment not in self._configurations:\n",
    "            raise ValueError(f\"Environment '{environment}' not found in configurations\")\n",
    "        \n",
    "        return self._configurations[environment].copy()\n",
    "    \n",
    "    def add_environment(self, environment, config_dict):\n",
    "        \"\"\"\n",
    "        Add a new environment configuration\n",
    "        \n",
    "        Args:\n",
    "            environment (str): Environment name\n",
    "            config_dict (dict): Configuration dictionary\n",
    "        \"\"\"\n",
    "        self._configurations[environment] = config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a3b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADLSConnector:\n",
    "    \"\"\"\n",
    "    Reusable code for connecting to ADLS with centralized configuration management\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, environment='nonprod', config_service=None):\n",
    "        \"\"\"\n",
    "        Initialize the ADLS connector\n",
    "        \n",
    "        Args:\n",
    "            environment (str): 'prod' or 'nonprod' to determine which config to use\n",
    "            config_service (ConfigurationService): Optional config service instance\n",
    "        \"\"\"\n",
    "        self.environment = environment\n",
    "        self.config_service = config_service or ConfigurationService()\n",
    "        self.env_config = self.config_service.get_configuration(environment)\n",
    "        self.config_dict = None\n",
    "        self.source_path = None\n",
    "        self.mount_point = None\n",
    "        self.is_mounted = False\n",
    "        \n",
    "    def setup_connection(self, \n",
    "                        storage_account_name, \n",
    "                        container_name, \n",
    "                        mount_name,\n",
    "                        subfolder_path=\"\",\n",
    "                        spn_scope=None):\n",
    "        \"\"\"\n",
    "        Set up the ADLS connection configuration\n",
    "        \n",
    "        Args:\n",
    "            storage_account_name (str): Name of your Azure storage account\n",
    "            container_name (str): Name of the container in storage account\n",
    "            mount_name (str): Local name for the mount point\n",
    "            subfolder_path (str): Optional subfolder path within container\n",
    "            spn_scope (str): Optional custom secret scope (uses default if not provided)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Use default secret scope from configuration if not provided\n",
    "        secret_scope = spn_scope or self.env_config['default-secret-scope']\n",
    "        \n",
    "        # Get credentials from Databricks secrets using configuration\n",
    "        try:\n",
    "            client_id = dbutils.secrets.get(secret_scope, self.env_config['client-id-key'])\n",
    "            client_secret = dbutils.secrets.get(secret_scope, self.env_config['client-secret-key'])\n",
    "            tenant_id = self.env_config['tenant-id']\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to retrieve secrets from scope '{secret_scope}': {str(e)}\")\n",
    "        \n",
    "        # Build Azure storage path\n",
    "        self.source_path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/{subfolder_path}\"\n",
    "        \n",
    "        # Set local mount point\n",
    "        self.mount_point = f\"/mnt/{mount_name}\"\n",
    "        \n",
    "        # Create OAuth configuration\n",
    "        self.config_dict = {\n",
    "            \"fs.azure.account.auth.type\": \"OAuth\",\n",
    "            \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "            \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "            \"fs.azure.account.oauth2.client.secret\": client_secret,\n",
    "            \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Done! Configuration set up for {self.environment} environment\")\n",
    "        print(f\"  Source: {self.source_path}\")\n",
    "        print(f\"  Mount: {self.mount_point}\")\n",
    "        print(f\"  Using secret scope: {secret_scope}\")\n",
    "        \n",
    "    def mount(self):\n",
    "        \"\"\"\n",
    "        Mount the ADLS storage to Databricks file system\n",
    "        \"\"\"\n",
    "        if not self.config_dict:\n",
    "            raise Exception(\"Configuration not set up. Call setup_connection() first.\")\n",
    "        \n",
    "        try:\n",
    "            dbutils.fs.mount(\n",
    "                source=self.source_path,\n",
    "                mount_point=self.mount_point,\n",
    "                extra_configs=self.config_dict\n",
    "            )\n",
    "            self.is_mounted = True\n",
    "            print(f\"Done! Successfully mounted {self.source_path} at {self.mount_point}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            if \"already mounted\" in str(e).lower():\n",
    "                self.is_mounted = True\n",
    "                print(f\" {self.mount_point} already mounted\")\n",
    "            else:\n",
    "                raise Exception(f\"Failed to mount ADLS: {str(e)}\")\n",
    "    \n",
    "    def unmount(self):\n",
    "        \"\"\"\n",
    "        Unmount the ADLS storage\n",
    "        \"\"\"\n",
    "        if not self.mount_point:\n",
    "            raise Exception(\"No mount point configured\")\n",
    "            \n",
    "        try:\n",
    "            dbutils.fs.unmount(self.mount_point)\n",
    "            self.is_mounted = False\n",
    "            print(f\"Done! Successfully unmounted {self.mount_point}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not unmount! , {self.mount_point}: {str(e)}\")\n",
    "    \n",
    "    def list_files(self, subfolder=\"\"):\n",
    "        \"\"\"\n",
    "        List files in the mounted storage\n",
    "        \n",
    "        Args:\n",
    "            subfolder (str): Optional subfolder to list\n",
    "            \n",
    "        Returns:\n",
    "            list: List of file information\n",
    "        \"\"\"\n",
    "        if not self.is_mounted:\n",
    "            raise Exception(\"Storage not mounted. Call mount() first.\")\n",
    "        \n",
    "        path = f\"{self.mount_point}/{subfolder}\" if subfolder else self.mount_point\n",
    "        return dbutils.fs.ls(path)\n",
    "    \n",
    "    def check_connection(self):\n",
    "        \"\"\"\n",
    "        Test the connection by listing the root directory\n",
    "        \"\"\"\n",
    "        try:\n",
    "            files = self.list_files()\n",
    "            print(f\"Done! Connection successful! Found {len(files)} items in root directory\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Connection failed: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "# Updated helper function\n",
    "def create_adls_connection(environment, storage_account, container, mount_name, subfolder=\"\", config_service=None):\n",
    "    \"\"\"\n",
    "    Quick helper function to create and mount ADLS connection\n",
    "    \n",
    "    Returns:\n",
    "        ADLSConnector: Configured and mounted connector\n",
    "    \"\"\"\n",
    "    connector = ADLSConnector(environment, config_service)\n",
    "    connector.setup_connection(storage_account, container, mount_name, subfolder)\n",
    "    connector.mount()\n",
    "    return connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connector\n",
    "adls = ADLSConnector(environment='prod')\n",
    "\n",
    "# Set up connection\n",
    "adls.setup_connection(\n",
    "    storage_account_name='myadls',\n",
    "    container_name='analytics-data',\n",
    "    secret_scope='my-secrets',\n",
    "    mount_name='analytics_prod',\n",
    "    subfolder_path='reports/2024'\n",
    ")\n",
    "\n",
    "# Mount the storage\n",
    "adls.mount()\n",
    "\n",
    "# Test connection\n",
    "adls.check_connection()\n",
    "\n",
    "# Use the mounted storage\n",
    "file_path = adls.get_file_path('monthly_report.csv')\n",
    "df = spark.read.csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-liner setup\n",
    "adls = create_adls_connection(\n",
    "    environment='nonprod',\n",
    "    storage_account='myadls',\n",
    "    container='analytics-data',\n",
    "    secret_scope='my-secrets',\n",
    "    mount_name='analytics_dev'\n",
    ")\n",
    "\n",
    "# Use it immediately\n",
    "files = adls.list_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302e12d",
   "metadata": {},
   "source": [
    "Print File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text_file(adls_connector, text_file_path):\n",
    "    \"\"\"\n",
    "    Print contents of a text file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get full file path\n",
    "        full_path = adls_connector.get_file_path(text_file_path)\n",
    "        \n",
    "        # Read and print the file\n",
    "        with open(full_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            print(f\"Contents of {text_file_path}:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(content)\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "        return content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading text file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "adls = create_adls_connection('nonprod', 'mystorageaccount', 'data', 'my-secrets', 'data_mount')\n",
    "content = print_text_file(adls, \"logs/process_log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32041c",
   "metadata": {},
   "source": [
    "CSV File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8485e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CSV file from your mounted ADLS\n",
    "df = spark.read.csv(\"/mnt/data_lake/your_file.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_csv_column(adls_connector, csv_file_path, column_index=2):\n",
    "    \"\"\"\n",
    "    Sum a specific column in a CSV file\n",
    "    \n",
    "    Args:\n",
    "        adls_connector: Your ADLS connector instance\n",
    "        csv_file_path: Relative path to CSV file\n",
    "        column_index: Column index (0-based, so 2 = 3rd column)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get full file path\n",
    "        full_path = adls_connector.get_file_path(csv_file_path)\n",
    "        \n",
    "        # Method 1: Using Spark (better for large files)\n",
    "        df = spark.read.csv(full_path, header=True, inferSchema=True)\n",
    "        columns = df.columns\n",
    "        column_name = columns[column_index]\n",
    "        \n",
    "        total = df.select(sum(col(column_name)).alias(\"total\")).collect()[0][\"total\"]\n",
    "        print(f\"Sum of column '{column_name}' (column {column_index + 1}): {total}\")\n",
    "        \n",
    "        return total\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "adls = create_adls_connection('nonprod', 'mystorageaccount', 'data', 'my-secrets', 'data_mount')\n",
    "total = sum_csv_column(adls, \"sales/monthly_sales.csv\", column_index=2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
